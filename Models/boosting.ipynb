{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Util.tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../challenge_data/X_train.csv')\n",
    "Y_train = pd.read_csv('../challenge_data/Y_train.csv')\n",
    "X_test = pd.read_csv('../challenge_data/X_test.csv')\n",
    "X_train_clean = X_train.drop(['COUNTRY'], axis=1)\n",
    "X_train_clean = preprocessing(X_train_clean, norm=True, pca=True)\n",
    "X_train_clean = pd.DataFrame(X_train_clean)\n",
    "X_train_clean.columns = X_train_clean.columns.astype(str)\n",
    "Y_train_clean = Y_train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, cv=5):\n",
    "    scores = []\n",
    "    for _ in range(cv):\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X_train_clean, Y_train_clean, test_size=0.2, random_state=np.random.randint(1, 100))\n",
    "        model.fit(X_train, Y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = spearmanr(Y_test, y_pred).correlation\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "    metric = np.mean(scores)\n",
    "\n",
    "    print('Spearman correlation for the train set: {:.1f}%'.format(100 * metric ))\n",
    "\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_ensemble(n_estimators, learning_rate, estimator, X, Y, cv=5):\n",
    "    best_n = 0\n",
    "    best_learning_rate = 0\n",
    "    best_result = float('-inf')\n",
    "    best_model = None\n",
    "\n",
    "    for i in n_estimators:\n",
    "        for j in learning_rate:  \n",
    "            if estimator == 'AdaBoost':\n",
    "                model = AdaBoostRegressor(DecisionTreeRegressor(max_depth=3), n_estimators=i, learning_rate=j, random_state=1)\n",
    "\n",
    "            elif estimator == 'GradientBoost':\n",
    "                model = GradientBoostingRegressor(n_estimators=i, learning_rate=j, random_state=1)\n",
    "                \n",
    "            elif estimator == 'XGBoost':\n",
    "                model = XGBRegressor(n_estimators=i, learning_rate=j, random_state=1)\n",
    "                \n",
    "            else:\n",
    "                model = lgb.LGBMRegressor(max_depth=2, n_estimators=i, learning_rate=j, random_state=1, min_child_samples=20)\n",
    "\n",
    "            scores = []\n",
    "            for _ in range(cv):\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=np.random.randint(1, 100))\n",
    "\n",
    "                model.fit(X_train, Y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "                score = spearmanr(Y_test, y_pred).correlation\n",
    "\n",
    "                scores.append(score)\n",
    "\n",
    "            # Calculate the mean score\n",
    "            mean_score = np.mean(scores)\n",
    "\n",
    "            # Check if the current model is the best\n",
    "            if mean_score > best_result:\n",
    "                best_result = mean_score\n",
    "                best_n = i\n",
    "                best_learning_rate = j\n",
    "                best_model = model\n",
    "                \n",
    "\n",
    "    print(f'The best parameters values are: learning_rate: {best_learning_rate}, n_estimators: {best_n}')    \n",
    "\n",
    "    return best_n, best_learning_rate, best_model, best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set: 20.0%\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeRegressor(max_depth=3)\n",
    "clf.fit(X_train_clean, Y_train_clean)\n",
    "ada = AdaBoostRegressor(clf, n_estimators=500, learning_rate=0.1, random_state=1)\n",
    "result = training(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters values are: learning_rate: 0.1, n_estimators: 310\n"
     ]
    }
   ],
   "source": [
    "n_estimators = np.arange(100, 600, 30)\n",
    "learning_rate = [0.01, 0.05, 0.1, 0.5, 1]\n",
    "best_n, best_learning_rate, best_model, best_result = grid_search_ensemble(n_estimators, learning_rate, 'AdaBoost', X_train_clean, Y_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set: 16.7%\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeRegressor(max_depth=3)\n",
    "clf.fit(X_train_clean, Y_train_clean)\n",
    "ada_best = AdaBoostRegressor(clf, n_estimators=310, learning_rate=0.1, random_state=1)\n",
    "result = training(ada_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set: 11.8%\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(max_depth=2, n_estimators=500, learning_rate=0.1, random_state=1)\n",
    "result = training(gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters values are: learning_rate: 0.01, n_estimators: 280\n"
     ]
    }
   ],
   "source": [
    "n_estimators = np.arange(100, 600, 30)\n",
    "learning_rate = [0.01, 0.05, 0.1, 0.5, 1]\n",
    "best_n, best_learning_rate, best_model, best_result = grid_search_ensemble(n_estimators, learning_rate, 'GradientBoost', X_train_clean, Y_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set: 19.1%\n"
     ]
    }
   ],
   "source": [
    "gb_best = GradientBoostingRegressor(max_depth=2, n_estimators=280, learning_rate=0.01, random_state=1)\n",
    "\n",
    "result = training(gb_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('../challenge_data/X_test.csv')\n",
    "X_test = X_test.drop(['COUNTRY'], axis=1)\n",
    "X_test_clean = preprocessing(X_test, norm=True, pca=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "submission(X_test, X_test_clean, gb_best, 'gb_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set: 12.7%\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth=2, n_estimators=500, learning_rate=0.1)\n",
    "result = training(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters values are: learning_rate: 0.01, n_estimators: 190\n"
     ]
    }
   ],
   "source": [
    "n_estimators = np.arange(100, 600, 30)\n",
    "learning_rate = [0.01, 0.05, 0.1, 0.5, 1]\n",
    "best_n, best_learning_rate, best_model, best_result = grid_search_ensemble(n_estimators, learning_rate, 'XGBoost', X_train_clean, Y_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set: 18.1%\n"
     ]
    }
   ],
   "source": [
    "xgb_best = XGBRegressor(max_depth=2, n_estimators=190, learning_rate=0.01)\n",
    "\n",
    "result = training(xgb_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Temp\\ipykernel_15256\\228817269.py:73: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  de_train_final.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "D:\\Temp\\ipykernel_15256\\228817269.py:74: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  de_train_final.fillna(method='bfill', inplace=True)  # Backward fill\n",
      "D:\\Temp\\ipykernel_15256\\228817269.py:75: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  de_test_final.fillna(method='ffill', inplace=True)\n",
      "D:\\Temp\\ipykernel_15256\\228817269.py:76: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  de_test_final.fillna(method='bfill', inplace=True)\n",
      "D:\\Temp\\ipykernel_15256\\228817269.py:77: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  fr_train_final.fillna(method='ffill', inplace=True)\n",
      "D:\\Temp\\ipykernel_15256\\228817269.py:78: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  fr_train_final.fillna(method='bfill', inplace=True)\n",
      "D:\\Temp\\ipykernel_15256\\228817269.py:79: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  fr_test_final.fillna(method='ffill', inplace=True)\n",
      "D:\\Temp\\ipykernel_15256\\228817269.py:80: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  fr_test_final.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "df_train = pd.read_csv('../challenge_data/X_train.csv').set_index('ID').sort_index()\n",
    "y_train = pd.read_csv('../challenge_data/Y_train.csv').set_index('ID').sort_index()\n",
    "df_test = pd.read_csv('../challenge_data/X_test.csv').set_index('ID').sort_index()\n",
    "\n",
    "\n",
    "de_train = df_train[df_train['COUNTRY'] == 'DE']\n",
    "fr_train = df_train[df_train['COUNTRY'] == 'FR']\n",
    "\n",
    "y_de_train = y_train[y_train.index.isin(de_train.index)]\n",
    "y_fr_train = y_train[y_train.index.isin(fr_train.index)]\n",
    "\n",
    "de_full = pd.concat([de_train, df_test[df_test['COUNTRY'] == 'DE']]).sort_index()\n",
    "fr_full = pd.concat([fr_train, df_test[df_test['COUNTRY'] == 'FR']]).sort_index()\n",
    "\n",
    "de_full.drop('COUNTRY', axis=1, inplace=True)\n",
    "fr_full.drop('COUNTRY', axis=1, inplace=True)\n",
    "de_full = de_full.join(de_full.shift(1), rsuffix='_prev_day')\n",
    "fr_full = fr_full.join(fr_full.shift(1), rsuffix='_prev_day')\n",
    "\n",
    "window_size = 50  # Example window size, can be adjusted\n",
    "# Calculate moving averages for each column\n",
    "for column in de_full.columns:\n",
    "    if de_full[column].isnull().any():\n",
    "        de_full[column+'_MA'] = de_full[column].rolling(window=window_size, min_periods=1).mean()\n",
    "for column in de_full.columns:\n",
    "    if '_MA' in column:\n",
    "        original_column = column.replace('_MA', '')\n",
    "        de_full[original_column].fillna(de_full[column], inplace=True)\n",
    "        \n",
    "\n",
    "for column in fr_full.columns:\n",
    "    if fr_full[column].isnull().any():\n",
    "        fr_full[column+'_MA'] = fr_full[column].rolling(window=window_size, min_periods=1).mean()\n",
    "for column in fr_full.columns:\n",
    "    if '_MA' in column:\n",
    "        original_column = column.replace('_MA', '')\n",
    "        fr_full[original_column].fillna(fr_full[column], inplace=True)\n",
    "\n",
    "# Remove the moving average columns after filling missing values\n",
    "de_full.drop([col for col in de_full.columns if '_MA' in col], axis=1, inplace=True)\n",
    "fr_full.drop([col for col in fr_full.columns if '_MA' in col], axis=1, inplace=True)\n",
    "\n",
    "de_test_final = de_full[de_full['DAY_ID'].isin(df_test[df_test['COUNTRY'] == 'DE']['DAY_ID'])]\n",
    "fr_test_final = fr_full[fr_full['DAY_ID'].isin(df_test[df_test['COUNTRY'] == 'FR']['DAY_ID'])]\n",
    "de_train_final = de_full[de_full['DAY_ID'].isin(df_train[df_train['COUNTRY'] == 'DE']['DAY_ID'])]\n",
    "fr_train_final = fr_full[fr_full['DAY_ID'].isin(df_train[df_train['COUNTRY'] == 'FR']['DAY_ID'])]\n",
    "\n",
    "columns_to_remove = [\n",
    "    \"DAY_ID\", \"FR_CONSUMPTION\", \"FR_DE_EXCHANGE\", \"FR_NET_EXPORT\",\n",
    "    \"DE_NET_IMPORT\", \"FR_NET_IMPORT\", \"FR_GAS\", \"FR_COAL\", \"FR_HYDRO\", \n",
    "    \"FR_NUCLEAR\", \"FR_SOLAR\", \"FR_WINDPOW\", \"FR_RESIDUAL_LOAD\", \n",
    "    \"FR_RAIN\", \"FR_WIND\", \"FR_TEMP\"\n",
    "]\n",
    "# Add columns with '_prev_day' suffix\n",
    "columns_to_remove += [col + '_prev_day' for col in columns_to_remove]\n",
    "# Remove the columns from de_train_final\n",
    "de_train_final = de_train_final.drop(columns=columns_to_remove, errors='ignore')\n",
    "de_test_final = de_test_final.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "columns_to_remove = [\n",
    "    \"DAY_ID\", \"DE_CONSUMPTION\", \"DE_FR_EXCHANGE\", \"DE_NET_EXPORT\",\n",
    "    \"FR_NET_IMPORT\", \"DE_NET_IMPORT\", \"DE_GAS\", \"DE_COAL\", \"DE_HYDRO\", \n",
    "    \"DE_NUCLEAR\", \"DE_SOLAR\", \"DE_WINDPOW\", \"DE_RESIDUAL_LOAD\", \n",
    "    \"DE_RAIN\", \"DE_WIND\", \"DE_TEMP\"\n",
    "]\n",
    "# Add columns with '_prev_day' suffix\n",
    "columns_to_remove += [col + '_prev_day' for col in columns_to_remove]\n",
    "# Remove the columns from de_train_final\n",
    "fr_train_final = fr_train_final.drop(columns=columns_to_remove, errors='ignore')\n",
    "fr_test_final = fr_test_final.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "de_train_final.fillna(method='ffill', inplace=True)  # Forward fill\n",
    "de_train_final.fillna(method='bfill', inplace=True)  # Backward fill\n",
    "de_test_final.fillna(method='ffill', inplace=True)\n",
    "de_test_final.fillna(method='bfill', inplace=True)\n",
    "fr_train_final.fillna(method='ffill', inplace=True)\n",
    "fr_train_final.fillna(method='bfill', inplace=True)\n",
    "fr_test_final.fillna(method='ffill', inplace=True)\n",
    "fr_test_final.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation for Linear Regression: 65.0%\n",
      "Spearman Correlation for Linear Regression: 16.2%\n",
      "Spearman Correlation for Linear Regression: 74.5%\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "### Training process -- XGB\n",
    "##########################################################\n",
    "\n",
    "# Assuming 'TARGET' is your target variable\n",
    "X = de_train_final\n",
    "y = y_de_train\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "# Train the model\n",
    "xgb_model = XGBRegressor(max_depth=2, n_estimators=500, learning_rate=0.1)\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = xgb_model.predict(x_test)\n",
    "\n",
    "# Calculate Spearman Correlation\n",
    "spearman_corr_lr = spearmanr(y_pred_lr, y_test).correlation\n",
    "print(f\"Spearman Correlation for Linear Regression: {spearman_corr_lr:.1%}\")\n",
    "\n",
    "de_train_pred = xgb_model.predict(X)\n",
    "de_train = de_train_final.reset_index()\n",
    "de_train['TARGET'] = de_train_pred\n",
    "de_train = de_train[['ID', 'TARGET']]\n",
    "de_test = xgb_model.predict(de_test_final)\n",
    "de_test_pred = de_test_final.reset_index()\n",
    "de_test_pred['TARGET'] = de_test\n",
    "de_test_pred = de_test_pred[['ID', 'TARGET']]\n",
    "\n",
    "# Assuming 'TARGET' is your target variable\n",
    "X = fr_train_final\n",
    "y = y_fr_train\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "# Train the model\n",
    "xgb_model = XGBRegressor(max_depth=2, n_estimators=500, learning_rate=0.1)\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = xgb_model.predict(x_test)\n",
    "\n",
    "# Calculate Spearman Correlation\n",
    "spearman_corr_lr = spearmanr(y_pred_lr, y_test).correlation\n",
    "print(f\"Spearman Correlation for Linear Regression: {spearman_corr_lr:.1%}\")\n",
    "\n",
    "fr_train_pred = xgb_model.predict(X)\n",
    "fr_result = fr_train_final.reset_index()\n",
    "fr_result['TARGET'] = fr_train_pred\n",
    "fr_result = fr_result[['ID', 'TARGET']]\n",
    "fr_test = xgb_model.predict(fr_test_final)\n",
    "fr_test_pred = fr_test_final.reset_index()\n",
    "fr_test_pred['TARGET'] = fr_test\n",
    "fr_test_pred = fr_test_pred[['ID', 'TARGET']]\n",
    "\n",
    "y_train = pd.read_csv('../challenge_data/Y_train.csv')\n",
    "train_pred = pd.DataFrame()\n",
    "train_pred['ID'] = y_train['ID']\n",
    "\n",
    "train_pred = train_pred.merge(de_train[['ID', 'TARGET']], on='ID', how='left')\n",
    "train_pred = train_pred.merge(fr_result[['ID', 'TARGET']], on='ID', how='left')\n",
    "\n",
    "train_pred['TARGET'] = train_pred['TARGET_x'].combine_first(train_pred['TARGET_y'])\n",
    "\n",
    "train_pred = train_pred.drop(['TARGET_x', 'TARGET_y'], axis=1)\n",
    "\n",
    "spearman_corr_lr = spearmanr(train_pred['TARGET'], y_train['TARGET']).correlation\n",
    "print(f\"Spearman Correlation for Linear Regression: {spearman_corr_lr:.1%}\")\n",
    "\n",
    "# SUBMISSION\n",
    "df_test = pd.read_csv('../challenge_data/X_test.csv')\n",
    "test_pred = pd.DataFrame()\n",
    "test_pred['ID'] = df_test['ID']\n",
    "test_pred = test_pred.merge(de_test_pred[['ID', 'TARGET']], on='ID', how='left')\n",
    "test_pred = test_pred.merge(fr_test_pred[['ID', 'TARGET']], on='ID', how='left')\n",
    "test_pred['TARGET'] = test_pred['TARGET_x'].combine_first(test_pred['TARGET_y'])\n",
    "test_pred = test_pred.drop(['TARGET_x', 'TARGET_y'], axis=1)\n",
    "test_pred.to_csv('./Submission/' + 'xgb_final' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred.to_csv('./Train submission/xgb_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation for Linear Regression: 58.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation for Linear Regression: 23.3%\n",
      "Spearman Correlation for Linear Regression: 52.8%\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "### Training process -- GradientBoosting\n",
    "##########################################################\n",
    "\n",
    "# Assuming 'TARGET' is your target variable\n",
    "X = de_train_final\n",
    "y = y_de_train\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "# Train the model\n",
    "model = GradientBoostingRegressor(max_depth=2, n_estimators=280, learning_rate=0.01, random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = model.predict(x_test)\n",
    "\n",
    "# Calculate Spearman Correlation\n",
    "spearman_corr_lr = spearmanr(y_pred_lr, y_test).correlation\n",
    "print(f\"Spearman Correlation for Linear Regression: {spearman_corr_lr:.1%}\")\n",
    "\n",
    "de_train_pred = model.predict(X)\n",
    "de_train = de_train_final.reset_index()\n",
    "de_train['TARGET'] = de_train_pred\n",
    "de_train = de_train[['ID', 'TARGET']]\n",
    "de_test = model.predict(de_test_final)\n",
    "de_test_pred = de_test_final.reset_index()\n",
    "de_test_pred['TARGET'] = de_test\n",
    "de_test_pred = de_test_pred[['ID', 'TARGET']]\n",
    "\n",
    "# Assuming 'TARGET' is your target variable\n",
    "X = fr_train_final\n",
    "y = y_fr_train\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "# Train the model\n",
    "model = GradientBoostingRegressor(max_depth=2, n_estimators=280, learning_rate=0.01, random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = model.predict(x_test)\n",
    "\n",
    "# Calculate Spearman Correlation\n",
    "spearman_corr_lr = spearmanr(y_pred_lr, y_test).correlation\n",
    "print(f\"Spearman Correlation for Linear Regression: {spearman_corr_lr:.1%}\")\n",
    "\n",
    "fr_train_pred = model.predict(X)\n",
    "fr_result = fr_train_final.reset_index()\n",
    "fr_result['TARGET'] = fr_train_pred\n",
    "fr_result = fr_result[['ID', 'TARGET']]\n",
    "fr_test = model.predict(fr_test_final)\n",
    "fr_test_pred = fr_test_final.reset_index()\n",
    "fr_test_pred['TARGET'] = fr_test\n",
    "fr_test_pred = fr_test_pred[['ID', 'TARGET']]\n",
    "\n",
    "y_train = pd.read_csv('../challenge_data/Y_train.csv')\n",
    "train_pred = pd.DataFrame()\n",
    "train_pred['ID'] = y_train['ID']\n",
    "\n",
    "train_pred = train_pred.merge(de_train[['ID', 'TARGET']], on='ID', how='left')\n",
    "train_pred = train_pred.merge(fr_result[['ID', 'TARGET']], on='ID', how='left')\n",
    "\n",
    "train_pred['TARGET'] = train_pred['TARGET_x'].combine_first(train_pred['TARGET_y'])\n",
    "\n",
    "train_pred = train_pred.drop(['TARGET_x', 'TARGET_y'], axis=1)\n",
    "\n",
    "spearman_corr_lr = spearmanr(train_pred['TARGET'], y_train['TARGET']).correlation\n",
    "print(f\"Spearman Correlation for Linear Regression: {spearman_corr_lr:.1%}\")\n",
    "\n",
    "# SUBMISSION\n",
    "df_test = pd.read_csv('../challenge_data/X_test.csv')\n",
    "test_pred = pd.DataFrame()\n",
    "test_pred['ID'] = df_test['ID']\n",
    "test_pred = test_pred.merge(de_test_pred[['ID', 'TARGET']], on='ID', how='left')\n",
    "test_pred = test_pred.merge(fr_test_pred[['ID', 'TARGET']], on='ID', how='left')\n",
    "test_pred['TARGET'] = test_pred['TARGET_x'].combine_first(test_pred['TARGET_y'])\n",
    "test_pred = test_pred.drop(['TARGET_x', 'TARGET_y'], axis=1)\n",
    "test_pred.to_csv('./Submission/' + 'gb_final' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred.to_csv('./Train submission/gb_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation for Linear Regression: 56.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation for Linear Regression: 7.2%\n",
      "Spearman Correlation for Linear Regression: 38.2%\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "### Training process -- AdaBoosting\n",
    "##########################################################\n",
    "\n",
    "# Assuming 'TARGET' is your target variable\n",
    "X = de_train_final\n",
    "y = y_de_train\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "# Train the model\n",
    "clf = DecisionTreeRegressor(max_depth=3)\n",
    "clf.fit(x_train, y_train)\n",
    "model = AdaBoostRegressor(clf, n_estimators=500, learning_rate=0.1, random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = model.predict(x_test)\n",
    "\n",
    "# Calculate Spearman Correlation\n",
    "spearman_corr_lr = spearmanr(y_pred_lr, y_test).correlation\n",
    "print(f\"Spearman Correlation for Linear Regression: {spearman_corr_lr:.1%}\")\n",
    "\n",
    "de_train_pred = model.predict(X)\n",
    "de_train = de_train_final.reset_index()\n",
    "de_train['TARGET'] = de_train_pred\n",
    "de_train = de_train[['ID', 'TARGET']]\n",
    "de_test = model.predict(de_test_final)\n",
    "de_test_pred = de_test_final.reset_index()\n",
    "de_test_pred['TARGET'] = de_test\n",
    "de_test_pred = de_test_pred[['ID', 'TARGET']]\n",
    "\n",
    "# Assuming 'TARGET' is your target variable\n",
    "X = fr_train_final\n",
    "y = y_fr_train\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "# Train the model\n",
    "clf = DecisionTreeRegressor(max_depth=3)\n",
    "clf.fit(x_train, y_train)\n",
    "model = AdaBoostRegressor(clf, n_estimators=500, learning_rate=0.1, random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = model.predict(x_test)\n",
    "\n",
    "# Calculate Spearman Correlation\n",
    "spearman_corr_lr = spearmanr(y_pred_lr, y_test).correlation\n",
    "print(f\"Spearman Correlation for Linear Regression: {spearman_corr_lr:.1%}\")\n",
    "\n",
    "fr_train_pred = model.predict(X)\n",
    "fr_result = fr_train_final.reset_index()\n",
    "fr_result['TARGET'] = fr_train_pred\n",
    "fr_result = fr_result[['ID', 'TARGET']]\n",
    "fr_test = model.predict(fr_test_final)\n",
    "fr_test_pred = fr_test_final.reset_index()\n",
    "fr_test_pred['TARGET'] = fr_test\n",
    "fr_test_pred = fr_test_pred[['ID', 'TARGET']]\n",
    "\n",
    "y_train = pd.read_csv('../challenge_data/Y_train.csv')\n",
    "train_pred = pd.DataFrame()\n",
    "train_pred['ID'] = y_train['ID']\n",
    "\n",
    "train_pred = train_pred.merge(de_train[['ID', 'TARGET']], on='ID', how='left')\n",
    "train_pred = train_pred.merge(fr_result[['ID', 'TARGET']], on='ID', how='left')\n",
    "\n",
    "train_pred['TARGET'] = train_pred['TARGET_x'].combine_first(train_pred['TARGET_y'])\n",
    "\n",
    "train_pred = train_pred.drop(['TARGET_x', 'TARGET_y'], axis=1)\n",
    "\n",
    "spearman_corr_lr = spearmanr(train_pred['TARGET'], y_train['TARGET']).correlation\n",
    "print(f\"Spearman Correlation for Linear Regression: {spearman_corr_lr:.1%}\")\n",
    "\n",
    "# SUBMISSION\n",
    "df_test = pd.read_csv('../challenge_data/X_test.csv')\n",
    "test_pred = pd.DataFrame()\n",
    "test_pred['ID'] = df_test['ID']\n",
    "test_pred = test_pred.merge(de_test_pred[['ID', 'TARGET']], on='ID', how='left')\n",
    "test_pred = test_pred.merge(fr_test_pred[['ID', 'TARGET']], on='ID', how='left')\n",
    "test_pred['TARGET'] = test_pred['TARGET_x'].combine_first(test_pred['TARGET_y'])\n",
    "test_pred = test_pred.drop(['TARGET_x', 'TARGET_y'], axis=1)\n",
    "test_pred.to_csv('./Submission/' + 'adab_final' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred.to_csv('./Train submission/adb_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
