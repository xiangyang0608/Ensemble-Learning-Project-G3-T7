{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import itertools as it\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import mutual_info_regression as mir\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder as onehot\n",
    "from sklearn import linear_model\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "import xgboost as xgb\n",
    "from itertools import product\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.deterministic import Fourier\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../challenge_data/X_train.csv')\n",
    "Y_train = pd.read_csv('../challenge_data/Y_train.csv')\n",
    "X_test = pd.read_csv('../challenge_data/X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Util.tools import *\n",
    "X_train_clean = fill_missing_with_average(X_train)\n",
    "X_test_clean = fill_missing_with_average(X_test)\n",
    "\n",
    "#drop those cols according to EDA\n",
    "X_train_clean=X_train_clean.drop([\"DE_FR_EXCHANGE\",\"DE_NET_IMPORT\",\"FR_NET_IMPORT\"],axis=1)\n",
    "X_test_clean=X_test_clean.drop([\"DE_FR_EXCHANGE\",\"DE_NET_IMPORT\",\"FR_NET_IMPORT\"],axis=1)\n",
    "\n",
    "#Split into DE & FR\n",
    "X_train_de = X_train_clean[X_train_clean['COUNTRY'] == 'DE']\n",
    "X_test_de = X_test_clean[X_test_clean['COUNTRY'] == 'DE']\n",
    "\n",
    "X_train_fr = X_train_clean[X_train_clean['COUNTRY'] == 'FR']\n",
    "X_test_fr = X_test_clean[X_test_clean['COUNTRY'] == 'FR']\n",
    "\n",
    "# merge TARGET\n",
    "X_train_de = pd.merge(X_train_de, Y_train, on='ID', how='inner').sort_values('DAY_ID')\n",
    "X_train_fr = pd.merge(X_train_fr, Y_train, on='ID', how='inner').sort_values('DAY_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(654, 32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select correlation bigger than 0.05 \n",
    "def get_sorted_correlations_and_features(X_train, threshold=0.05):\n",
    "    correlations = {}\n",
    "    for column in X_train.columns:\n",
    "        if column == 'TARGET':  \n",
    "            continue\n",
    "        corr, _ = spearmanr(X_train[column], X_train['TARGET'])\n",
    "        correlations[column] = corr\n",
    "\n",
    "    corr_df = pd.DataFrame(list(correlations.items()), columns=['Feature', 'Correlation'])\n",
    "    corr_df['Absolute_Correlation'] = corr_df['Correlation'].abs()\n",
    "    sorted_corr_df = corr_df.sort_values('Absolute_Correlation', ascending=False)\n",
    "    \n",
    "    selected_features = sorted_corr_df[sorted_corr_df['Absolute_Correlation'] >= threshold]['Feature']\n",
    "    features_selected = selected_features.tolist()\n",
    "    \n",
    "    return sorted_corr_df, features_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features for DE:\n",
      "['DE_RESIDUAL_LOAD', 'DE_NET_EXPORT', 'DE_WINDPOW', 'DE_GAS', 'DE_HYDRO', 'FR_WINDPOW', 'DE_COAL', 'DE_WIND', 'DE_LIGNITE', 'FR_DE_EXCHANGE', 'FR_WIND', 'FR_GAS', 'DE_CONSUMPTION', 'FR_RAIN', 'FR_HYDRO']\n",
      "Selected Features for FR:\n",
      "['CARBON_RET', 'GAS_RET', 'FR_WINDPOW', 'DE_HYDRO', 'DE_WINDPOW', 'DE_NET_EXPORT', 'FR_HYDRO', 'FR_COAL', 'DE_RAIN', 'COAL_RET', 'DE_RESIDUAL_LOAD', 'DE_CONSUMPTION']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4916: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4916: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n"
     ]
    }
   ],
   "source": [
    "sorted_corr_df_de, features_selected_de = get_sorted_correlations_and_features(X_train_de)\n",
    "print(\"Selected Features for DE:\")\n",
    "print(features_selected_de)\n",
    "\n",
    "sorted_corr_df_fr, features_selected_fr = get_sorted_correlations_and_features(X_train_fr)\n",
    "print(\"Selected Features for FR:\")\n",
    "print(features_selected_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_trainde, X_testde, Y_trainde, Y_testde = train_test_split(X_train_de[features_selected_de], X_train_de['TARGET'], test_size=0.2, random_state=42)\n",
    "X_trainfr, X_testfr, Y_trainfr, Y_testfr = train_test_split(X_train_fr[features_selected_fr], X_train_fr['TARGET'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def metric_train(output, truth):\n",
    "    return spearmanr(output, truth).correlation\n",
    "\n",
    "\n",
    "def get_model(model_name, best_param=None):\n",
    "    if model_name == 'dt':\n",
    "        model = DecisionTreeRegressor(**(best_param if best_param else {}))\n",
    "    elif model_name == 'bagging_ridge':\n",
    "        base_model = Ridge(**(best_param['base_model'] if best_param and 'base_model' in best_param else {}))\n",
    "        model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42, **(best_param['model'] if best_param and 'model' in best_param else {}))\n",
    "    elif model_name == 'extra_trees':\n",
    "        model = ExtraTreesRegressor(**(best_param if best_param else {}))\n",
    "    elif model_name == 'rf':\n",
    "        model = RandomForestRegressor(**(best_param if best_param else {}))\n",
    "    elif model_name == 'bagging_knn':\n",
    "        base_model = KNeighborsRegressor(**(best_param['base_model'] if best_param and 'base_model' in best_param else {}))\n",
    "        model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42, **(best_param['model'] if best_param and 'model' in best_param else {}))\n",
    "    elif model_name == 'bagging_svr':\n",
    "        base_model = SVR(**(best_param['base_model'] if best_param and 'base_model' in best_param else {}))\n",
    "        model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42, **(best_param['model'] if best_param and 'model' in best_param else {}))\n",
    "    elif model_name == 'bagging_linear':\n",
    "        base_model = LinearRegression(**(best_param['base_model'] if best_param and 'base_model' in best_param else {}))\n",
    "        model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42, **(best_param['model'] if best_param and 'model' in best_param else {}))\n",
    "    elif model_name == 'adaboost':\n",
    "        model = AdaBoostRegressor(**(best_param if best_param else {}))\n",
    "    elif model_name == 'gradient_boosting':\n",
    "        model = GradientBoostingRegressor(**(best_param if best_param else {}))\n",
    "    else:\n",
    "        raise ValueError('Unknown Model')\n",
    "    return model\n",
    "        \n",
    "scorer_train = make_scorer(metric_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_names = [\n",
    "    'dt',  # Decision Tree Regressor\n",
    "    'bagging_ridge',  # Bagging model based on Ridge regression\n",
    "    'extra_trees',  # Extra Trees Regressor\n",
    "    'rf',  # Random Forest Regressor\n",
    "    'bagging_knn',  # Bagging model based on KNN regression\n",
    "    'bagging_svr',  # Bagging model based on SVR\n",
    "    'bagging_linear',  # Bagging model based on Linear regression\n",
    "    'adaboost',  # AdaBoost Regressor\n",
    "    'gradient_boosting'  # Gradient Boosting Regressor\n",
    "]\n",
    "\n",
    "# Train and evaluate models\n",
    "results = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    model = get_model(model_name)\n",
    "    \n",
    "    # Train on DE dataset\n",
    "    model.fit(X_trainde, Y_trainde)\n",
    "    predictions_de = model.predict(X_testde)\n",
    "    score_de = metric_train(predictions_de, Y_testde)\n",
    "    \n",
    "    # Train on FR dataset\n",
    "    model.fit(X_trainfr, Y_trainfr)\n",
    "    predictions_fr = model.predict(X_testfr)  \n",
    "    score_fr = metric_train(predictions_fr, Y_testfr)\n",
    "    \n",
    "    # Overall Score\n",
    "    predictions_overall = np.concatenate((predictions_de, predictions_fr))\n",
    "    truth_overall = np.concatenate((Y_testde, Y_testfr))\n",
    "    score_overall = metric_train(predictions_overall, truth_overall)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'DE_Train_Score': score_de,\n",
    "        'FR_Train_Score': score_fr,\n",
    "        'Overall_Score': score_overall  \n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model  DE_Train_Score  FR_Train_Score  Overall_Score\n",
      "0                 dt        0.284955        0.077280       0.175760\n",
      "1      bagging_ridge        0.491419        0.158929       0.313878\n",
      "2        extra_trees        0.199631        0.133809       0.156962\n",
      "3                 rf        0.291290        0.186128       0.225199\n",
      "4        bagging_knn        0.134548        0.102892       0.107535\n",
      "5        bagging_svr        0.412729        0.245307       0.320654\n",
      "6     bagging_linear        0.491704        0.156625       0.314120\n",
      "7           adaboost        0.348586        0.102280       0.196787\n",
      "8  gradient_boosting        0.294186        0.265961       0.268494\n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tune only 1.bagging_ridge 2,extra_trees 3,random_forest 4,bagging_svr 5,bagging_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random_Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def rf_hyperparameter_optimization(X, y, cv=5, n_trials=10, seed=42):\n",
    "    def objective(trial):\n",
    "        param = {\n",
    "            \"n_estimators\": 100,  \n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 64),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 2, 64),\n",
    "            \"max_features\": trial.suggest_float(\"max_features\", 0.2, 1.0),\n",
    "            \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 2, 64),\n",
    "            \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 1e-2, 1.0, log=True),\n",
    "            \"max_samples\": trial.suggest_float(\"max_samples\", 0.5, 1.0),\n",
    "            \"ccp_alpha\": trial.suggest_float(\"ccp_alpha\", 1e-2, 1.0, log=True),\n",
    "        }\n",
    "\n",
    "        model = RandomForestRegressor(random_state=seed, **param)\n",
    "        \n",
    "        scores = cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\")\n",
    "        rmse_scores = np.sqrt(-scores)\n",
    "        return np.mean(rmse_scores)  \n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    return study.best_params\n",
    "\n",
    "rf_best_paramsde = rf_hyperparameter_optimization(X_trainde, Y_trainde, cv=5, n_trials=10, seed=42)\n",
    "rf_best_paramsfr = rf_hyperparameter_optimization(X_trainfr, Y_trainfr, cv=5, n_trials=10, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_best_paramsde {'max_depth': 12, 'min_samples_split': 54, 'min_samples_leaf': 38, 'max_features': 0.5205609222342362, 'max_leaf_nodes': 23, 'min_impurity_decrease': 0.014787554791665753, 'max_samples': 0.6142665282311632, 'ccp_alpha': 0.013510592133611757}\n",
      "rf_best_paramsfr {'max_depth': 8, 'min_samples_split': 19, 'min_samples_leaf': 46, 'max_features': 0.2755871091358061, 'max_leaf_nodes': 64, 'min_impurity_decrease': 0.1546686048571105, 'max_samples': 0.5479920782838656, 'ccp_alpha': 0.09273007854536494}\n"
     ]
    }
   ],
   "source": [
    "print(\"rf_best_paramsde\", rf_best_paramsde)\n",
    "print(\"rf_best_paramsfr\", rf_best_paramsfr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging_Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_ridge_hyperparameter_optimization(X, y, cv=5, n_trials=10, seed=42):\n",
    "    def objective(trial):\n",
    "\n",
    "        ridge_param = {\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 0.1, 5.0, log=True),\n",
    "            \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "        }\n",
    "        ridge_model = Ridge(**ridge_param)\n",
    "        \n",
    "\n",
    "        bagging_param = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 5, 50),\n",
    "            \"max_samples\": trial.suggest_float(\"max_samples\", 0.5, 1.0),\n",
    "            \"max_features\": trial.suggest_float(\"max_features\", 0.5, 1.0),\n",
    "            \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "            \"bootstrap_features\": trial.suggest_categorical(\"bootstrap_features\", [True, False]),\n",
    "        }\n",
    "        model = BaggingRegressor(base_estimator=ridge_model, random_state=seed, **bagging_param)\n",
    "        \n",
    "        scores = cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\")\n",
    "        rmse_scores = np.sqrt(-scores)\n",
    "        return np.mean(rmse_scores)  \n",
    "\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    return study.best_params\n",
    "\n",
    "\n",
    "bagging_ridge_best_paramsde = bagging_ridge_hyperparameter_optimization(X_trainde, Y_trainde, cv=5, n_trials=10, seed=42)\n",
    "bagging_ridge_best_paramsfr = bagging_ridge_hyperparameter_optimization(X_trainfr, Y_trainfr, cv=5, n_trials=10, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging_ridge_best_paramsde {'alpha': 0.13127964086795652, 'fit_intercept': False, 'n_estimators': 9, 'max_samples': 0.9052323196872838, 'max_features': 0.60663852707117, 'bootstrap': False, 'bootstrap_features': False}\n",
      "bagging_ridge_best_paramsfr {'alpha': 2.4491178209446103, 'fit_intercept': False, 'n_estimators': 41, 'max_samples': 0.522053845558303, 'max_features': 0.6379497644797867, 'bootstrap': True, 'bootstrap_features': True}\n"
     ]
    }
   ],
   "source": [
    "print(\"bagging_ridge_best_paramsde\", bagging_ridge_best_paramsde)\n",
    "print(\"bagging_ridge_best_paramsfr\", bagging_ridge_best_paramsfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra_Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_trees_hyperparameter_optimization(X, y, cv=5, n_trials=10, seed=42):\n",
    "    def objective(trial):\n",
    "        param = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 5, 30),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 14),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 14),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"auto\", \"sqrt\", \"log2\"]),\n",
    "            \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "        }\n",
    "        \n",
    "        model = ExtraTreesRegressor(random_state=seed, **param)\n",
    "        \n",
    "        scores = cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\")\n",
    "        rmse_scores = np.sqrt(-scores)\n",
    "        return np.mean(rmse_scores)  \n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    return study.best_params\n",
    "\n",
    "extra_trees_best_paramsde = extra_trees_hyperparameter_optimization(X_trainde, Y_trainde, cv=5, n_trials=10, seed=42)\n",
    "extra_trees_best_paramsfr = extra_trees_hyperparameter_optimization(X_trainfr, Y_trainfr, cv=5, n_trials=10, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra_trees_best_paramsde {'n_estimators': 243, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_features': 'log2', 'bootstrap': False}\n",
      "extra_trees_best_paramsfr {'n_estimators': 419, 'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 14, 'max_features': 'sqrt', 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "print(\"extra_trees_best_paramsde\", extra_trees_best_paramsde)\n",
    "print(\"extra_trees_best_paramsfr\", extra_trees_best_paramsfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bagging_svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_svr_hyperparameter_optimization(X, y, cv=5, n_trials=10, seed=42):\n",
    "    def objective(trial):\n",
    "        svr_param = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.5, 10.0, log=True),\n",
    "            \"epsilon\": trial.suggest_float(\"epsilon\", 0.05, 1.0, log=True),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]),\n",
    "        }\n",
    "        svr_model = SVR(**svr_param)\n",
    "        \n",
    "        bagging_param = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 5, 50),\n",
    "            \"max_samples\": trial.suggest_float(\"max_samples\", 0.5, 1.0),\n",
    "            \"max_features\": trial.suggest_float(\"max_features\", 0.5, 1.0),\n",
    "            \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "            \"bootstrap_features\": trial.suggest_categorical(\"bootstrap_features\", [True, False]),\n",
    "        }\n",
    "        model = BaggingRegressor(base_estimator=svr_model, random_state=seed, **bagging_param)\n",
    "\n",
    "        scores = cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\")\n",
    "        rmse_scores = np.sqrt(-scores)\n",
    "        return np.mean(rmse_scores) \n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    return study.best_params\n",
    "\n",
    "\n",
    "bagging_svr_best_paramsde = bagging_svr_hyperparameter_optimization(X_trainde, Y_trainde, cv=5, n_trials=10, seed=42)\n",
    "bagging_svr_best_paramsfr = bagging_svr_hyperparameter_optimization(X_trainfr, Y_trainfr, cv=5, n_trials=10, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging_svr_best_paramsde {'C': 3.1448128468266963, 'epsilon': 0.4784378232407096, 'kernel': 'linear', 'n_estimators': 22, 'max_samples': 0.7194185583803373, 'max_features': 0.6261535214367662, 'bootstrap': False, 'bootstrap_features': False}\n",
      "bagging_svr_best_paramsfr {'C': 8.672280895584546, 'epsilon': 0.46639272686518213, 'kernel': 'linear', 'n_estimators': 30, 'max_samples': 0.5812234331859144, 'max_features': 0.6238399887187047, 'bootstrap': True, 'bootstrap_features': True}\n"
     ]
    }
   ],
   "source": [
    "print(\"bagging_svr_best_paramsde\", bagging_svr_best_paramsde)\n",
    "print(\"bagging_svr_best_paramsfr\", bagging_svr_best_paramsfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bagging_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_linear_hyperparameter_optimization(X, y, cv=5, n_trials=10, seed=42):\n",
    "    def objective(trial):\n",
    "        bagging_param = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 5, 100),\n",
    "            \"max_samples\": trial.suggest_float(\"max_samples\", 0.5, 1.0),\n",
    "            \"max_features\": trial.suggest_float(\"max_features\", 0.5, 1.0),\n",
    "            \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "            \"bootstrap_features\": trial.suggest_categorical(\"bootstrap_features\", [True, False]),\n",
    "        }\n",
    "        base_model = LinearRegression()\n",
    "        model = BaggingRegressor(base_estimator=base_model, random_state=seed, **bagging_param)\n",
    "        \n",
    "        scores = cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\")\n",
    "        rmse_scores = np.sqrt(-scores)\n",
    "        return np.mean(rmse_scores)  \n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    return study.best_params\n",
    "\n",
    "bagging_linear_best_paramsde = bagging_linear_hyperparameter_optimization(X_trainde, Y_trainde, cv=5, n_trials=10, seed=42)\n",
    "bagging_linear_best_paramsfr = bagging_linear_hyperparameter_optimization(X_trainfr, Y_trainfr, cv=5, n_trials=10, seed=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging_linear_best_paramsde: {'n_estimators': 70, 'max_samples': 0.7809284628702564, 'max_features': 0.5948601849583957, 'bootstrap': False, 'bootstrap_features': False}\n",
      "bagging_linear_best_paramsfr: {'n_estimators': 28, 'max_samples': 0.748160199580953, 'max_features': 0.527913910908094, 'bootstrap': True, 'bootstrap_features': True}\n"
     ]
    }
   ],
   "source": [
    "print(\"bagging_linear_best_paramsde:\", bagging_linear_best_paramsde)\n",
    "print(\"bagging_linear_best_paramsfr:\", bagging_linear_best_paramsfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2659610723114215"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(random_state=42)\n",
    "model.set_params(**rf_best_paramsde)  \n",
    "    \n",
    "model.fit(X_trainde, Y_trainde)\n",
    "predictions_de = model.predict(X_testde)  \n",
    "score_de = metric_train(predictions_fr, Y_testfr)\n",
    "score_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4916: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'rf', 'DE_Train_Score': 0.4532479874776388, 'FR_Train_Score': nan, 'Overall_Score': 0.2798921041440074}\n",
      "{'Model': 'bagging_ridge', 'DE_Train_Score': 0.4914188282647586, 'FR_Train_Score': 0.15892912856697147, 'Overall_Score': 0.31387770975233054}\n",
      "{'Model': 'extra_trees', 'DE_Train_Score': 0.3791815742397138, 'FR_Train_Score': 0.21396308829529365, 'Overall_Score': 0.27309770108556763}\n",
      "{'Model': 'bagging_svr', 'DE_Train_Score': 0.4127292039355993, 'FR_Train_Score': 0.24530683754529967, 'Overall_Score': 0.32065422949143874}\n",
      "{'Model': 'bagging_linear', 'DE_Train_Score': 0.4917039355992845, 'FR_Train_Score': 0.15662514699882402, 'Overall_Score': 0.31411993466594074}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "def apply_best_params(model, best_params):\n",
    "    # This function assumes best_params is a dictionary of parameters to be set\n",
    "    model.set_params(**best_params)\n",
    "    return model\n",
    "\n",
    "for model_name, best_params_de, best_params_fr in [\n",
    "    # Model names and best_params placeholders\n",
    "]:\n",
    "    # Initialize the model\n",
    "    model_de = get_model(model_name)\n",
    "    model_fr = get_model(model_name)\n",
    "    \n",
    "    # Apply best parameters - this step is conceptual\n",
    "    # You would need to ensure that best_params_* variables are dictionaries of parameters\n",
    "    model_de = apply_best_params(model_de, best_params_de)\n",
    "    model_fr = apply_best_params(model_fr, best_params_fr)\n",
    "\n",
    "\n",
    "for model_name, best_params_de, best_params_fr in [\n",
    "    ('rf', rf_best_paramsde, rf_best_paramsfr),\n",
    "    ('bagging_ridge', bagging_ridge_best_paramsde, bagging_ridge_best_paramsfr),\n",
    "    ('extra_trees', extra_trees_best_paramsde, extra_trees_best_paramsfr),\n",
    "    ('bagging_svr', bagging_svr_best_paramsde, bagging_svr_best_paramsfr),\n",
    "    ('bagging_linear', bagging_linear_best_paramsde, bagging_linear_best_paramsfr),\n",
    "]:\n",
    "\n",
    "    model_de = get_model(model_name, best_params_de)\n",
    "    model_de.fit(X_trainde, Y_trainde)\n",
    "    predictions_de = model_de.predict(X_testde)\n",
    "    score_de = metric_train(predictions_de, Y_testde)\n",
    "    \n",
    "    model_fr = get_model(model_name, best_params_fr)\n",
    "    model_fr.fit(X_trainfr, Y_trainfr)\n",
    "    predictions_fr = model_fr.predict(X_testfr)\n",
    "    score_fr = metric_train(predictions_fr, Y_testfr)\n",
    "\n",
    "    predictions_overall = np.concatenate((predictions_de, predictions_fr))\n",
    "    truth_overall = np.concatenate((Y_testde, Y_testfr))\n",
    "    score_overall = metric_train(predictions_overall, truth_overall)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'DE_Train_Score': score_de,\n",
    "        'FR_Train_Score': score_fr,\n",
    "        'Overall_Score': score_overall,\n",
    "    })\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DE=X_train_de[features_selected_de]\n",
    "Y_DE = X_train_de['TARGET']\n",
    "\n",
    "X_FR=X_train_fr[features_selected_fr]\n",
    "Y_FR = X_train_fr['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store overall predictions for each model\n",
    "predictions_overall = {}\n",
    "for model_name, best_params_de, best_params_fr in [\n",
    "    ('rf', rf_best_paramsde, rf_best_paramsfr),\n",
    "    ('bagging_ridge', bagging_ridge_best_paramsde, bagging_ridge_best_paramsfr),\n",
    "    ('extra_trees', extra_trees_best_paramsde, extra_trees_best_paramsfr),\n",
    "    ('bagging_svr', bagging_svr_best_paramsde, bagging_svr_best_paramsfr),\n",
    "    ('bagging_linear', bagging_linear_best_paramsde, bagging_linear_best_paramsfr),\n",
    "]:\n",
    "\n",
    "    model_de = get_model(model_name, best_params_de)\n",
    "    model_de.fit(X_DE, Y_DE)\n",
    "    predictions_de = model_de.predict(X_DE)\n",
    "\n",
    "    model_fr = get_model(model_name, best_params_fr)\n",
    "    model_fr.fit(X_FR, Y_FR)\n",
    "    predictions_fr = model_fr.predict(X_FR)\n",
    "\n",
    "    # Store the combined predictions in the dictionary\n",
    "    predictions_overall[model_name] = np.concatenate((predictions_de, predictions_fr))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ./Train submission/rf_train.csv\n",
      "Saved predictions to ./Train submission/bagging_ridge_train.csv\n",
      "Saved predictions to ./Train submission/extra_trees_train.csv\n",
      "Saved predictions to ./Train submission/bagging_svr_train.csv\n",
      "Saved predictions to ./Train submission/bagging_linear_train.csv\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train_de is a DataFrame that includes an 'ID' column\n",
    "ids_de = X_train_de['ID']\n",
    "ids_fr = X_train_fr['ID']  \n",
    "import os\n",
    "output_dir = './Train submission'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "for model_name, predictions in predictions_overall.items():\n",
    "    # Concatenate DE and FR IDs\n",
    "    ids_overall = pd.concat([ids_de, ids_fr], ignore_index=True)\n",
    "    \n",
    "    # Combine the IDs with the predictions\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'ID': ids_overall,\n",
    "        'TARGET': predictions\n",
    "    })\n",
    "    \n",
    "    # Define the filename using the model name\n",
    "    filename = f\"{model_name}_train.csv\"\n",
    "    full_path = os.path.join(output_dir, filename)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file in the specified directory\n",
    "    predictions_df.to_csv(full_path, index=False)\n",
    "    print(f\"Saved predictions to {full_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_DE=X_test_de[features_selected_de]\n",
    "SUB_FR=X_test_fr[features_selected_fr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((289, 15), (365, 12))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUB_DE.shape,SUB_FR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ./Submission/rf_test.csv\n",
      "Saved predictions to ./Submission/bagging_ridge_test.csv\n",
      "Saved predictions to ./Submission/extra_trees_test.csv\n",
      "Saved predictions to ./Submission/bagging_svr_test.csv\n",
      "Saved predictions to ./Submission/bagging_linear_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "submissions_overall_test = {}\n",
    "sub_output_dir = './Submission'\n",
    "\n",
    "for model_name, best_params_de, best_params_fr in [\n",
    "    ('rf', rf_best_paramsde, rf_best_paramsfr),\n",
    "    ('bagging_ridge', bagging_ridge_best_paramsde, bagging_ridge_best_paramsfr),\n",
    "    ('extra_trees', extra_trees_best_paramsde, extra_trees_best_paramsfr),\n",
    "    ('bagging_svr', bagging_svr_best_paramsde, bagging_svr_best_paramsfr),\n",
    "    ('bagging_linear', bagging_linear_best_paramsde, bagging_linear_best_paramsfr),\n",
    "]:\n",
    "    # Initialize and fit the model for DE\n",
    "    model_de = get_model(model_name, best_params_de)\n",
    "    model_de.fit(X_DE, Y_DE)\n",
    "    predictions_de = model_de.predict(SUB_DE)\n",
    "\n",
    "    # Initialize and fit the model for FR\n",
    "    model_fr = get_model(model_name, best_params_fr)\n",
    "    model_fr.fit(X_FR, Y_FR)\n",
    "    predictions_fr = model_fr.predict(SUB_FR)\n",
    "\n",
    "    # Store the predictions in the dictionary\n",
    "    submissions_overall_test[model_name] = np.concatenate((predictions_de, predictions_fr))\n",
    "\n",
    "# Assuming X_train_de and X_train_fr DataFrames include an 'ID' column\n",
    "ids_de = X_test_de['ID']\n",
    "ids_fr = X_test_fr['ID']\n",
    "\n",
    "# Save the predictions to CSV files in the specified directories\n",
    "for model_name, predictions in submissions_overall_test.items():\n",
    "    # Concatenate DE and FR IDs\n",
    "    ids_overall = pd.concat([ids_de, ids_fr], ignore_index=True)\n",
    "    \n",
    "    # Combine the IDs with the predictions\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'ID': ids_overall,\n",
    "        'TARGET': predictions\n",
    "    })\n",
    "    \n",
    "    # Define the filenames using the model name\n",
    "    filename = f\"{model_name}_test.csv\"\n",
    "\n",
    "    full_path = os.path.join(sub_output_dir, filename)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file in the specified directory\n",
    "    predictions_df.to_csv(full_path, index=False)\n",
    "    print(f\"Saved predictions to {full_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd75362e27048f1ead3b65beb4812b1da3d387150557ce53b099093c32022a5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
