{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, Lasso, ElasticNet\n",
    "from sklearn.feature_selection import mutual_info_regression as mir\n",
    "from sklearn.model_selection import train_test_split, KFold, TimeSeriesSplit\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder as onehot\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape, mean_squared_error\n",
    "import xgboost as xgb\n",
    "# from mlxtend.regressor import StackingCVRegressor\n",
    "from scipy.stats import spearmanr, stats\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess, Fourier\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from scipy import signal\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_train_final = pd.read_csv('./data/de_train_final.csv')\n",
    "y_de_train = pd.read_csv('./data/y_de_train.csv')\n",
    "fr_train_final = pd.read_csv('./data/fr_train_final.csv')\n",
    "y_fr_train = pd.read_csv('./data/y_fr_train.csv')\n",
    "\n",
    "de_test_final = pd.read_csv('./data/de_test_final.csv')\n",
    "fr_test_final = pd.read_csv('./data/fr_test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"de_train_final with shape:\", de_train_final.shape)\n",
    "print(\"y_de_train with shape:\", y_de_train.shape)\n",
    "print(\"fr_train_final with shape:\", fr_train_final.shape)\n",
    "print(\"y_fr_train with shape:\", y_fr_train.shape)\n",
    "print(\"de_test_final with shape:\", de_test_final.shape)\n",
    "print(\"fr_test_final with shape:\", fr_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = de_train_final\n",
    "y = y_de_train\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "# Train the model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = lr_model.predict(x_test)\n",
    "\n",
    "# Calculate Spearman Correlation\n",
    "spearman_corr_lr, _ = spearmanr(y_test, y_pred_lr)\n",
    "spearman_corr_lr_value = spearman_corr_lr.item()\n",
    "\n",
    "# Print\n",
    "print(f\"Spearman Correlation for Linear Regression: {spearman_corr_lr_value:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_de = de_train_final\n",
    "y_de = y_de_train\n",
    "X_trainde, X_testde, Y_trainde, Y_testde = train_test_split(X_de, y_de, test_size=0.30, random_state=42)\n",
    "\n",
    "X_fr = fr_train_final\n",
    "y_fr = y_fr_train\n",
    "X_trainfr, X_testfr, Y_trainfr, Y_testfr = train_test_split(X_fr, y_fr, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def metric_train(output, truth):\n",
    "    return spearmanr(output, truth).correlation\n",
    "\n",
    "\n",
    "def get_model(model_name, best_param=None):\n",
    "    if model_name == 'dt':\n",
    "        model = DecisionTreeRegressor(**(best_param if best_param else {}))\n",
    "    elif model_name == 'bagging_ridge':\n",
    "        base_model = Ridge(**(best_param['base_model'] if best_param and 'base_model' in best_param else {}))\n",
    "        model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42, **(best_param['model'] if best_param and 'model' in best_param else {}))\n",
    "    elif model_name == 'extra_trees':\n",
    "        model = ExtraTreesRegressor(**(best_param if best_param else {}))\n",
    "    elif model_name == 'rf':\n",
    "        model = RandomForestRegressor(**(best_param if best_param else {}))\n",
    "    elif model_name == 'bagging_knn':\n",
    "        base_model = KNeighborsRegressor(**(best_param['base_model'] if best_param and 'base_model' in best_param else {}))\n",
    "        model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42, **(best_param['model'] if best_param and 'model' in best_param else {}))\n",
    "    elif model_name == 'bagging_svr':\n",
    "        base_model = SVR(**(best_param['base_model'] if best_param and 'base_model' in best_param else {}))\n",
    "        model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42, **(best_param['model'] if best_param and 'model' in best_param else {}))\n",
    "    elif model_name == 'bagging_linear':\n",
    "        base_model = LinearRegression(**(best_param['base_model'] if best_param and 'base_model' in best_param else {}))\n",
    "        model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42, **(best_param['model'] if best_param and 'model' in best_param else {}))\n",
    "    elif model_name == 'adaboost':\n",
    "        model = AdaBoostRegressor(**(best_param if best_param else {}))\n",
    "    elif model_name == 'gradient_boosting':\n",
    "        model = GradientBoostingRegressor(**(best_param if best_param else {}))\n",
    "    elif model_name == 'xgboost':\n",
    "        model = XGBRegressor(**(best_param if best_param else {}))\n",
    "    else:\n",
    "        raise ValueError('Unknown Model')\n",
    "    return model\n",
    "        \n",
    "scorer_train = make_scorer(metric_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'dt',  # Decision Tree Regressor\n",
    "    'bagging_ridge',  # Bagging model based on Ridge regression\n",
    "    'extra_trees',  # Extra Trees Regressor\n",
    "    'rf',  # Random Forest Regressor\n",
    "    'bagging_knn',  # Bagging model based on KNN regression\n",
    "    'bagging_svr',  # Bagging model based on SVR\n",
    "    'bagging_linear',  # Bagging model based on Linear regression\n",
    "    'adaboost',  # AdaBoost Regressor\n",
    "    'gradient_boosting' , # Gradient Boosting Regressor\n",
    "    'xgboost' #Xgboost Regressor\n",
    "]\n",
    "\n",
    "# Train and evaluate models\n",
    "results = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    model = get_model(model_name)\n",
    "    \n",
    "    # Train on DE dataset\n",
    "    model.fit(X_trainde, Y_trainde)\n",
    "    predictions_de = model.predict(X_testde)\n",
    "    score_de = metric_train(predictions_de, Y_testde)\n",
    "    \n",
    "    # Train on FR dataset\n",
    "    model.fit(X_trainfr, Y_trainfr)\n",
    "    predictions_fr = model.predict(X_testfr)  \n",
    "    score_fr = metric_train(predictions_fr, Y_testfr)\n",
    "    \n",
    "    # Overall Score\n",
    "    predictions_overall = np.concatenate((predictions_de, predictions_fr))\n",
    "    truth_overall = np.concatenate((Y_testde, Y_testfr))\n",
    "    score_overall = metric_train(predictions_overall, truth_overall)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'DE_Score': score_de,\n",
    "        'FR_Score': score_fr,\n",
    "        'Overall_Score': score_overall  \n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost model on German dataset\n",
    "model_de = XGBRegressor()\n",
    "model_de.fit(X_trainde, Y_trainde)\n",
    "\n",
    "# Obtain feature importances and feature names\n",
    "feature_importances_de = model_de.feature_importances_\n",
    "feature_names_de = X_trainde.columns.tolist()  # Get feature names\n",
    "\n",
    "# Create DataFrame for feature names and their importance scores\n",
    "feature_importance_de = pd.DataFrame({'Feature Name': feature_names_de, 'Importance': feature_importances_de})\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "feature_importance_de.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "# Visualize feature importance for the German dataset\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importance_de['Feature Name'], feature_importance_de['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance for DE Dataset')\n",
    "plt.gca().invert_yaxis()  # To display the most important feature at the top\n",
    "plt.show()\n",
    "\n",
    "# Train XGBoost model on French dataset\n",
    "model_fr = XGBRegressor()\n",
    "model_fr.fit(X_trainfr, Y_trainfr)\n",
    "\n",
    "# Obtain feature importances and feature names\n",
    "feature_importances_fr = model_fr.feature_importances_\n",
    "feature_names_fr = X_trainfr.columns.tolist()  # Get feature names\n",
    "\n",
    "# Create DataFrame for feature names and their importance scores\n",
    "feature_importance_fr = pd.DataFrame({'Feature Name': feature_names_fr, 'Importance': feature_importances_fr})\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "feature_importance_fr.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "# Visualize feature importance for the French dataset\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importance_fr['Feature Name'], feature_importance_fr['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance for FR Dataset')\n",
    "plt.gca().invert_yaxis()  # To display the most important feature at the top\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = results_df.nlargest(5, 'Overall_Score')['Model']\n",
    "\n",
    "estimators = []\n",
    "for model_name in best_models:\n",
    "    if model_name == 'dt':\n",
    "        estimator = DecisionTreeRegressor()\n",
    "    elif model_name == 'bagging_ridge':\n",
    "        estimator = BaggingRegressor(base_estimator=RidgeCV())\n",
    "    elif model_name == 'extra_trees':\n",
    "        estimator = ExtraTreesRegressor()\n",
    "    elif model_name == 'rf':\n",
    "        estimator = RandomForestRegressor()\n",
    "    elif model_name == 'bagging_knn':\n",
    "        estimator = BaggingRegressor(base_estimator=KNeighborsRegressor())\n",
    "    elif model_name == 'bagging_svr':\n",
    "        estimator = BaggingRegressor(base_estimator=SVR())\n",
    "    elif model_name == 'bagging_linear':\n",
    "        estimator = BaggingRegressor(base_estimator=LinearRegression())\n",
    "    elif model_name == 'adaboost':\n",
    "        estimator = AdaBoostRegressor()\n",
    "    elif model_name == 'gradient_boosting':\n",
    "        estimator = GradientBoostingRegressor()\n",
    "    elif model_name == 'xgboost':\n",
    "        estimator = XGBRegressor()\n",
    "    else:\n",
    "        raise ValueError('Unknown Model')\n",
    "    \n",
    "    estimators.append((model_name, estimator))\n",
    "\n",
    "# Define Stacking Model\n",
    "stacking_model = StackingCVRegressor(regressors=[estimator for _, estimator in estimators], \n",
    "                                     meta_regressor=RidgeCV(),\n",
    "                                     cv=5,\n",
    "                                     use_features_in_secondary=True,\n",
    "                                     random_state=42)\n",
    "\n",
    "# Train and evaluate models\n",
    "results = []\n",
    "\n",
    "model_name = 'stacking_model'\n",
    "\n",
    "model = stacking_model\n",
    "    \n",
    "# Train on DE dataset\n",
    "model.fit(X_trainde, Y_trainde)\n",
    "predictions_de = model.predict(X_testde)\n",
    "score_de = metric_train(predictions_de, Y_testde)\n",
    "\n",
    "# Train on FR dataset\n",
    "model.fit(X_trainfr, Y_trainfr)\n",
    "predictions_fr = model.predict(X_testfr)  \n",
    "score_fr = metric_train(predictions_fr, Y_testfr)\n",
    "\n",
    "# Overall Score\n",
    "predictions_overall = np.concatenate((predictions_de, predictions_fr))\n",
    "truth_overall = np.concatenate((Y_testde, Y_testfr))\n",
    "score_overall = metric_train(predictions_overall, truth_overall)\n",
    "\n",
    "results.append({\n",
    "    'Model': model_name,\n",
    "    'DE_Score': score_de,\n",
    "    'FR_Score': score_fr,\n",
    "    'Overall_Score': score_overall  \n",
    "})\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_train_pred = stacking_model.predict(X_de)\n",
    "de_train = de_train_final.reset_index()\n",
    "de_train['TARGET'] = de_train_pred\n",
    "de_train = de_train[['ID', 'TARGET']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Coefficient of each base model\n",
    "\n",
    "meta_coef = stacking_model.meta_regr_.coef_\n",
    "meta_coef_base_models = meta_coef[:len(estimators)]\n",
    "model_coefficients = dict(zip([name for name, _ in estimators], meta_coef_base_models))\n",
    "\n",
    "for model_name, coef in model_coefficients.items():\n",
    "    print(f\"{model_name}: {coef}\")\n",
    "\n",
    "coefficients_df = pd.DataFrame(list(model_coefficients.items()), columns=['Model', 'Coefficient'])\n",
    "print(coefficients_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_test = stacking_model.predict(de_test_final)\n",
    "de_test_pred = de_test_final.reset_index()\n",
    "de_test_pred['TARGET'] = de_test\n",
    "de_test_pred = de_test_pred[['ID', 'TARGET']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_train_pred = stacking_model.predict(X_fr)\n",
    "fr_result = fr_train_final.reset_index()\n",
    "fr_result['TARGET'] = fr_train_pred\n",
    "fr_result = fr_result[['ID', 'TARGET']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_test = stacking_model.predict(fr_test_final)\n",
    "fr_test_pred = fr_test_final.reset_index()\n",
    "fr_test_pred['TARGET'] = fr_test\n",
    "fr_test_pred = fr_test_pred[['ID', 'TARGET']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../challenge_data/X_test.csv')\n",
    "test_pred = pd.DataFrame()\n",
    "test_pred['ID'] = df_test['ID']\n",
    "\n",
    "test_pred = test_pred.merge(de_test_pred[['ID', 'TARGET']], on='ID', how='left')\n",
    "test_pred = test_pred.merge(fr_test_pred[['ID', 'TARGET']], on='ID', how='left')\n",
    "test_pred['TARGET'] = test_pred['TARGET_x'].combine_first(test_pred['TARGET_y'])\n",
    "test_pred = test_pred.drop(['TARGET_x', 'TARGET_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_pred.to_csv('./Submission/' + 'stack1_test' + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd75362e27048f1ead3b65beb4812b1da3d387150557ce53b099093c32022a5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
