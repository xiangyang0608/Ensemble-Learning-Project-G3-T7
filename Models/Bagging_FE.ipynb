{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import itertools as it\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import mutual_info_regression as mir\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder as onehot\n",
    "from sklearn import linear_model\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "import xgboost as xgb\n",
    "from itertools import product\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.deterministic import Fourier\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_train_final = pd.read_csv('./data/de_train_final.csv')\n",
    "y_de_train = pd.read_csv('./data/y_de_train.csv')\n",
    "fr_train_final = pd.read_csv('./data/fr_train_final.csv')\n",
    "y_fr_train = pd.read_csv('./data/y_fr_train.csv')\n",
    "\n",
    "de_test_final = pd.read_csv('./data/de_test_final.csv')\n",
    "fr_test_final = pd.read_csv('./data/fr_test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_train_final with shape: (643, 35)\n",
      "y_de_train with shape: (643, 1)\n",
      "fr_train_final with shape: (851, 35)\n",
      "y_fr_train with shape: (851, 1)\n",
      "de_test_final with shape: (289, 35)\n",
      "fr_test_final with shape: (365, 35)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"de_train_final with shape:\", de_train_final.shape)\n",
    "print(\"y_de_train with shape:\", y_de_train.shape)\n",
    "print(\"fr_train_final with shape:\", fr_train_final.shape)\n",
    "print(\"y_fr_train with shape:\", y_fr_train.shape)\n",
    "print(\"de_test_final with shape:\", de_test_final.shape)\n",
    "print(\"fr_test_final with shape:\", fr_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation for Linear Regression: 71.0%\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'TARGET' is your target variable\n",
    "X = de_train_final\n",
    "y = y_de_train\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Train the model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = lr_model.predict(x_test)\n",
    "\n",
    "# Calculate Spearman Correlation\n",
    "spearman_corr_lr, _ = spearmanr(y_test, y_pred_lr)\n",
    "spearman_corr_lr_value = spearman_corr_lr.item()\n",
    "\n",
    "# Print\n",
    "print(f\"Spearman Correlation for Linear Regression: {spearman_corr_lr_value:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "\n",
    "X_de = de_train_final\n",
    "y_de = y_de_train\n",
    "\n",
    "# Split the data\n",
    "X_trainde, X_testde, Y_trainde, Y_testde = train_test_split(X_de, y_de, test_size=0.30, random_state=42)\n",
    "\n",
    "X_fr = fr_train_final\n",
    "y_fr = y_fr_train\n",
    "\n",
    "# Split the data\n",
    "X_trainfr, X_testfr, Y_trainfr, Y_testfr = train_test_split(X_fr, y_fr, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def metric_train(output, truth):\n",
    "    return spearmanr(output, truth).correlation\n",
    "\n",
    "\n",
    "def get_model(model_name, best_param=None):\n",
    "    if model_name == 'dt':\n",
    "        model = DecisionTreeRegressor(**(best_param if best_param else {}))\n",
    "    elif model_name == 'bagging_ridge':\n",
    "        base_model = Ridge(**(best_param['base_model'] if best_param and 'base_model' in best_param else {}))\n",
    "        model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42, **(best_param['model'] if best_param and 'model' in best_param else {}))\n",
    "    elif model_name == 'extra_trees':\n",
    "        model = ExtraTreesRegressor(**(best_param if best_param else {}))\n",
    "    elif model_name == 'rf':\n",
    "        model = RandomForestRegressor(**(best_param if best_param else {}))\n",
    "    elif model_name == 'bagging_knn':\n",
    "        base_model = KNeighborsRegressor(**(best_param['base_model'] if best_param and 'base_model' in best_param else {}))\n",
    "        model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42, **(best_param['model'] if best_param and 'model' in best_param else {}))\n",
    "    elif model_name == 'bagging_svr':\n",
    "        base_model = SVR(**(best_param['base_model'] if best_param and 'base_model' in best_param else {}))\n",
    "        model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42, **(best_param['model'] if best_param and 'model' in best_param else {}))\n",
    "    elif model_name == 'bagging_linear':\n",
    "        base_model = LinearRegression(**(best_param['base_model'] if best_param and 'base_model' in best_param else {}))\n",
    "        model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42, **(best_param['model'] if best_param and 'model' in best_param else {}))\n",
    "    elif model_name == 'adaboost':\n",
    "        model = AdaBoostRegressor(**(best_param if best_param else {}))\n",
    "    elif model_name == 'gradient_boosting':\n",
    "        model = GradientBoostingRegressor(**(best_param if best_param else {}))\n",
    "    elif model_name == 'xgboost':\n",
    "        model = XGBRegressor(**(best_param if best_param else {}))\n",
    "    else:\n",
    "        raise ValueError('Unknown Model')\n",
    "    return model\n",
    "        \n",
    "scorer_train = make_scorer(metric_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'dt',  # Decision Tree Regressor\n",
    "    'bagging_ridge',  # Bagging model based on Ridge regression\n",
    "    'extra_trees',  # Extra Trees Regressor\n",
    "    'rf',  # Random Forest Regressor\n",
    "    'bagging_knn',  # Bagging model based on KNN regression\n",
    "    'bagging_svr',  # Bagging model based on SVR\n",
    "    'bagging_linear',  # Bagging model based on Linear regression\n",
    "    'adaboost',  # AdaBoost Regressor\n",
    "    'gradient_boosting' , # Gradient Boosting Regressor\n",
    "    'xgboost' #Xgboost Regressor\n",
    "]\n",
    "\n",
    "# Train and evaluate models\n",
    "results = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    model = get_model(model_name)\n",
    "    \n",
    "    # Train on DE dataset\n",
    "    model.fit(X_trainde, Y_trainde)\n",
    "    predictions_de = model.predict(X_testde)\n",
    "    score_de = metric_train(predictions_de, Y_testde)\n",
    "    \n",
    "    # Train on FR dataset\n",
    "    model.fit(X_trainfr, Y_trainfr)\n",
    "    predictions_fr = model.predict(X_testfr)  \n",
    "    score_fr = metric_train(predictions_fr, Y_testfr)\n",
    "    \n",
    "    # Overall Score\n",
    "    predictions_overall = np.concatenate((predictions_de, predictions_fr))\n",
    "    truth_overall = np.concatenate((Y_testde, Y_testfr))\n",
    "    score_overall = metric_train(predictions_overall, truth_overall)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'DE_Score': score_de,\n",
    "        'FR_Score': score_fr,\n",
    "        'Overall_Score': score_overall  \n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model  DE_Score  FR_Score  Overall_Score\n",
      "0                 dt  0.511747  0.012576       0.251714\n",
      "1      bagging_ridge  0.768485  0.232256       0.526632\n",
      "2        extra_trees  0.714527  0.090024       0.401900\n",
      "3                 rf  0.681588  0.094142       0.394513\n",
      "4        bagging_knn -0.242485  0.123651      -0.042472\n",
      "5        bagging_svr -0.075682  0.089942      -0.035366\n",
      "6     bagging_linear  0.772510  0.228310       0.525331\n",
      "7           adaboost  0.567545  0.100448       0.313814\n",
      "8  gradient_boosting  0.665576  0.074267       0.373179\n",
      "9            xgboost  0.698499  0.084659       0.398867\n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "best_models = results_df.nlargest(5, 'Overall_Score')['Model']\n",
    "\n",
    "estimators = []\n",
    "for model_name in best_models:\n",
    "    if model_name == 'dt':\n",
    "        estimator = DecisionTreeRegressor()\n",
    "    elif model_name == 'bagging_ridge':\n",
    "        estimator = BaggingRegressor(base_estimator=RidgeCV())\n",
    "    elif model_name == 'extra_trees':\n",
    "        estimator = ExtraTreesRegressor()\n",
    "    elif model_name == 'rf':\n",
    "        estimator = RandomForestRegressor()\n",
    "    elif model_name == 'bagging_knn':\n",
    "        estimator = BaggingRegressor(base_estimator=KNeighborsRegressor())\n",
    "    elif model_name == 'bagging_svr':\n",
    "        estimator = BaggingRegressor(base_estimator=SVR())\n",
    "    elif model_name == 'bagging_linear':\n",
    "        estimator = BaggingRegressor(base_estimator=LinearRegression())\n",
    "    elif model_name == 'adaboost':\n",
    "        estimator = AdaBoostRegressor()\n",
    "    elif model_name == 'gradient_boosting':\n",
    "        estimator = GradientBoostingRegressor()\n",
    "    elif model_name == 'xgboost':\n",
    "        estimator = XGBRegressor()\n",
    "    else:\n",
    "        raise ValueError('Unknown Model')\n",
    "    \n",
    "    estimators.append((model_name, estimator))\n",
    "\n",
    "# Define Stacking Model\n",
    "stacking_model = StackingCVRegressor(regressors=[estimator for _, estimator in estimators], \n",
    "                                     meta_regressor=RidgeCV(),\n",
    "                                     cv=5,\n",
    "                                     use_features_in_secondary=True,\n",
    "                                     random_state=42)\n",
    "\n",
    "# Train and evaluate models\n",
    "results = []\n",
    "\n",
    "model_name = 'stacking_model'\n",
    "\n",
    "model = stacking_model\n",
    "    \n",
    "# Train on DE dataset\n",
    "model.fit(X_trainde, Y_trainde)\n",
    "predictions_de = model.predict(X_testde)\n",
    "score_de = metric_train(predictions_de, Y_testde)\n",
    "\n",
    "# Train on FR dataset\n",
    "model.fit(X_trainfr, Y_trainfr)\n",
    "predictions_fr = model.predict(X_testfr)  \n",
    "score_fr = metric_train(predictions_fr, Y_testfr)\n",
    "\n",
    "# Overall Score\n",
    "predictions_overall = np.concatenate((predictions_de, predictions_fr))\n",
    "truth_overall = np.concatenate((Y_testde, Y_testfr))\n",
    "score_overall = metric_train(predictions_overall, truth_overall)\n",
    "\n",
    "results.append({\n",
    "    'Model': model_name,\n",
    "    'DE_Score': score_de,\n",
    "    'FR_Score': score_fr,\n",
    "    'Overall_Score': score_overall  \n",
    "})\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     bagging_ridge\n",
      "6    bagging_linear\n",
      "2       extra_trees\n",
      "9           xgboost\n",
      "3                rf\n",
      "Name: Model, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Model  DE_Score  FR_Score  Overall_Score\n",
      "0  stacking_model  0.742934   0.24532       0.509885\n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but BaggingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but BaggingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "de_train_pred = stacking_model.predict(X_de)\n",
    "de_train = de_train_final.reset_index()\n",
    "de_train['TARGET'] = de_train_pred\n",
    "de_train = de_train[['ID', 'TARGET']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging_ridge: -0.0009605481247803027\n",
      "bagging_linear: 0.8515205068203806\n",
      "extra_trees: 0.1993143445118956\n",
      "xgboost: -0.09044735126659581\n",
      "rf: -0.4095876826086659\n",
      "            Model  Coefficient\n",
      "0   bagging_ridge    -0.000961\n",
      "1  bagging_linear     0.851521\n",
      "2     extra_trees     0.199314\n",
      "3         xgboost    -0.090447\n",
      "4              rf    -0.409588\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 你的模型拟合代码...\n",
    "\n",
    "# 拟合完模型后，我们可以尝试获取元回归器的系数\n",
    "meta_coef = stacking_model.meta_regr_.coef_\n",
    "\n",
    "# 如果使用了特征在二级模型中，基模型的预测和原始特征都会被作为新特征\n",
    "# 因此，系数的数量可能会超过基模型的数量\n",
    "# 这里我们只关注基模型的预测对应的系数\n",
    "meta_coef_base_models = meta_coef[:len(estimators)]\n",
    "\n",
    "# 将每个模型的名称和对应的系数结合起来\n",
    "model_coefficients = dict(zip([name for name, _ in estimators], meta_coef_base_models))\n",
    "\n",
    "# 打印每个模型的系数\n",
    "for model_name, coef in model_coefficients.items():\n",
    "    print(f\"{model_name}: {coef}\")\n",
    "\n",
    "# 可选：将模型名称和系数转换为DataFrame以便更好地可视化\n",
    "coefficients_df = pd.DataFrame(list(model_coefficients.items()), columns=['Model', 'Coefficient'])\n",
    "\n",
    "print(coefficients_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but BaggingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but BaggingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/zhengwan/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "de_test = stacking_model.predict(de_test_final)\n",
    "de_test_pred = de_test_final.reset_index()\n",
    "de_test_pred['TARGET'] = de_test\n",
    "de_test_pred = de_test_pred[['ID', 'TARGET']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_train_pred = stacking_model.predict(X_fr)\n",
    "fr_result = fr_train_final.reset_index()\n",
    "fr_result['TARGET'] = fr_train_pred\n",
    "fr_result = fr_result[['ID', 'TARGET']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_test = stacking_model.predict(fr_test_final)\n",
    "fr_test_pred = fr_test_final.reset_index()\n",
    "fr_test_pred['TARGET'] = fr_test\n",
    "fr_test_pred = fr_test_pred[['ID', 'TARGET']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../challenge_data/X_test.csv')\n",
    "test_pred = pd.DataFrame()\n",
    "test_pred['ID'] = df_test['ID']\n",
    "\n",
    "test_pred = test_pred.merge(de_test_pred[['ID', 'TARGET']], on='ID', how='left')\n",
    "test_pred = test_pred.merge(fr_test_pred[['ID', 'TARGET']], on='ID', how='left')\n",
    "test_pred['TARGET'] = test_pred['TARGET_x'].combine_first(test_pred['TARGET_y'])\n",
    "test_pred = test_pred.drop(['TARGET_x', 'TARGET_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1115</td>\n",
       "      <td>0.096813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1202</td>\n",
       "      <td>-0.187547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1194</td>\n",
       "      <td>0.058015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1084</td>\n",
       "      <td>0.108519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1135</td>\n",
       "      <td>-0.418156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>879</td>\n",
       "      <td>-2.972887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>673</td>\n",
       "      <td>-1.265886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>1641</td>\n",
       "      <td>0.147184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>712</td>\n",
       "      <td>6.535001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>1060</td>\n",
       "      <td>0.365528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>654 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID    TARGET\n",
       "0    1115  0.096813\n",
       "1    1202 -0.187547\n",
       "2    1194  0.058015\n",
       "3    1084  0.108519\n",
       "4    1135 -0.418156\n",
       "..    ...       ...\n",
       "649   879 -2.972887\n",
       "650   673 -1.265886\n",
       "651  1641  0.147184\n",
       "652   712  6.535001\n",
       "653  1060  0.365528\n",
       "\n",
       "[654 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_pred.to_csv('./Submission/' + 'stack1_test' + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd75362e27048f1ead3b65beb4812b1da3d387150557ce53b099093c32022a5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
